import sys
import os
import pandas as pd
from utils.file_utils import get_first_directory_name, list_zip_files, compresser_dossier, supprimer_fichier
from utils.df_utils import create_database_structure, rename_attribut_values, harmonize_attribut, process_files_in_directory, calculer_sommeSynt_page3, calculer_sommeSynt_page2, verif_autoprod, verif_surplus
from datetime import datetime
import numpy as np
import subprocess
import shutil
from utils.database_utils import log_to_database, insert_data_to_mysql, remove_duplicates, delete_test_logs
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)


def call_another_program(repertoire, mail, mail_password, subject, num_boucle, periode):
   """
   Appeler un autre programme et transmettre les données.

   :param mdp (String): Mot de passe pour décrypter le dossier compressé
   :param repertoire (String): Chemin vers le répertoire contenant les données.
   :param mail (String): Adresse e-mail destinataire pour le mail de fin
   :param mail_password (String): Mot de passe associé à l'adresse e-mail.
   :param subject (String): Objet de l'e-mail.
   :param num_boucle (int): Numéro de la boucle d'autoconsommation.
   :param periode (str): Période (dateDebut_dateFin).
   
   """
   # Définit le chemin du programme à exécuter
   program_path = "/home/ubuntu/CEpublicationEXPL/src/cli/report_generator_cli.py"
   # Prépare les arguments à passer au programme
   args = [repertoire, mail, mail_password, subject, num_boucle, periode]
   
   try:
       # Exécute le programme externe en passant les arguments
       subprocess.run(["python3", program_path, *args], check=True)
   except subprocess.CalledProcessError as e:
       # Gère les erreurs en cas de problème lors de l'exécution du programme
        log_to_database(num_boucle, periode, datetime.now(), "", f"Erreur lors de l'appel du programme externe 'report_generator.py' : {e}", 2, "ERROR")


def main():
    """
    Fonction principale du programme de traitement des données.
    
    Cette fonction effectue les étapes suivantes :
    1. Vérifie que le nombre d'arguments fournis en ligne de commande est correct. Si ce n'est pas le cas, affiche un
       message d'utilisation et quitte le programme.
    2. Récupère les arguments de la ligne de commande (répertoire, adresse e-mail, mot de passe e-mail, objet de l'e-mail).
    3. Vérifie si le répertoire spécifié existe. S'il n'existe pas, affiche un message d'erreur et quitte le programme.
    4. Construit le chemin vers le fichier de journalisation (logfile.log) dans le répertoire spécifié.
    5. Extrait l'ID de la boucle et les dates de début et de fin à partir du nom du répertoire.
    6. Vérifie si le format des dates est valide.
    7. Récupère le premier sous-répertoire dans le répertoire spécifié en appelant la fonction `get_first_directory_name`.
    8. Construit le chemin vers le sous-répertoire.
    9. Crée la structure de la base de données en appelant la fonction `create_database_structure`.
    10. Traite les fichiers dans le sous-répertoire en appelant la fonction `process_files_in_directory` et récupère
        les DataFrames résultants.
    11. Concatène tous les DataFrames en un seul.
    12. Réindexe le DataFrame résultant avec les colonnes du DataFrame de base et remplit les valeurs manquantes avec NaN.
    13. Ajoute les lignes du DataFrame résultant au DataFrame de base.
    14. Renomme les valeurs des attributs dans le DataFrame en appelant la fonction `rename_attribut_values`.
    15. Récupère la liste des fichiers ZIP dans le répertoire spécifié en appelant la fonction `list_zip_files`.
    16. Compresse le sous-répertoire en appelant la fonction `compresser_dossier`.
    17. Si la compression réussit, supprime les fichiers ZIP existants dans le répertoire en appelant la fonction
        `supprimer_fichier`.
    18. Supprime le sous-répertoire en appelant `shutil.rmtree`.
    19. Crée un dictionnaire de correspondance pour les attributs.
    20. Pour chaque granularité unique, PRM unique et attribut unique :
        a. Harmonise le nom de l'attribut en appelant la fonction `harmonize_attribut`.
        b. Trie le DataFrame par PRM et attribut.
        c. Initialise la somme à 0.
        d. Calcule la somme des valeurs divisée par la granularité.
        e. Appelle les fonctions `calculer_sommeSynt_page3` ou `calculer_sommeSynt_page2` selon l'attribut harmonisé.
    21. Appelle les fonctions `verif_autoprod` et `verif_surplus` sur le DataFrame.
    22. Insere les données du dataFrame dans la table 'Mesure' de la base de données.
    23. Supprime les doublons de la table 'Mesure' de la base de données.
    24. Supprime les logs correspondant aux tests dans la table 'Log'.
    25. Appelle la fonction `call_another_program` en passant le répertoire, l'adresse e-mail, le mot de passe e-mail
        et l'objet de l'e-mail.
    
    :return: None
    """
   
    # Vérifie que le nombre d'arguments fournis en ligne de commande est correct.
    if len(sys.argv) != 7:
        print("Utilisation : python3 script.py <repertoire> <mail> <mail_password> <subject> <num_boucle> <periode>")
        sys.exit(1)
    
    # Récupère les arguments de la ligne de commande
    repertoire = sys.argv[1]
    mail = sys.argv[2]
    mail_password = sys.argv[3]
    subject = sys.argv[4]
    num_boucle = sys.argv[5]
    periode = sys.argv[6]
    
    
    # Vérifier si le répertoire existe
    if not os.path.isdir(repertoire):
        print(f"Le répertoire {repertoire} n'existe pas.")
        sys.exit(1)
    
    log_to_database(num_boucle, periode, datetime.now(), "data_processor.py", "Programme externe appelé avec succès.", 1, "INFO")
    
    # Extrait l'ID de la boucle et les dates de début et de fin à partir du nom du répertoire
    rep = repertoire.split("_")
    id_boucle = os.path.basename(rep[0])
    try:
        date_debut = datetime.strptime(rep[1], "%d%m%Y")
        date_fin = datetime.strptime(rep[2], "%d%m%Y")
    except ValueError:
        try:
            date_debut = datetime.strptime(rep[2], "%d%m%Y")
            date_fin = datetime.strptime(rep[3], "%d%m%Y")
        except ValueError:
            # Enregistre un message d'erreur dans le journal si le format des dates est invalide
            log_to_database(num_boucle, periode, datetime.now(), "", f"Format de date invalide dans le nom du répertoire {repertoire}", 2, "ERROR")
            sys.exit(1)
    
    if len(rep) == 4: # Si on fait du rattrapage (le dossier est sous la forme numBoucle_Personne Morale_dateDebut_dateFin)
        dossier = os.path.basename(repertoire)
        dossier_path = repertoire
    else:    
        # Récupère le premier sous-répertoire dans le répertoire spécifié
        dossier = get_first_directory_name(repertoire)
        # Construit le chemin vers le sous-répertoire
        dossier_path = os.path.join(repertoire, dossier)
        
        if dossier is None:
            log_to_database(num_boucle, periode, datetime.now(), "", f"Aucun sous-répertoire trouvé dans {repertoire}", 2, "ERROR")
            sys.exit(1)
    
    # Créer la structure de la base de données
    df = create_database_structure(num_boucle, periode)
    
    # Traite les fichiers dans le sous-répertoire et récupère les DataFrames résultants
    data_frames = process_files_in_directory(dossier_path, id_boucle, date_debut, date_fin, periode)
    
    # Concaténer tous les DataFrames en un seul
    data_frames = pd.concat(data_frames, ignore_index=True)
    
    # Réindexer data_frames avec les colonnes de df et remplir les valeurs manquantes avec NaN
    data_frames = data_frames.reindex(columns=df.columns, fill_value=np.nan)
    
    # Ajouter les lignes de data_frames à df
    df = pd.concat([df, data_frames], ignore_index=True)
    
    # Renomme les valeurs des attributs dans le DataFrame
    df = rename_attribut_values(df)
    
    # Récupère la liste des fichiers ZIP dans le répertoire spécifié
    zip_files = list_zip_files(repertoire)
    
    # Compresse le sous-répertoire
    cmp_dos = compresser_dossier(dossier_path, dossier_path, num_boucle, periode)
    
    # Si la compression réussit, supprime les fichiers ZIP existants dans le répertoire (sauf le dernier dossier compressé)
    if cmp_dos :
        for zip_name in zip_files :
            zip_path = os.path.join(repertoire, zip_name)
            supprimer_fichier(zip_path, num_boucle, periode)
    
    # Supprimer le dossier une fois le traitement terminé
    try:
        shutil.rmtree(dossier_path)
        log_to_database(num_boucle, periode, datetime.now(), f"{dossier_path}", "Suppression du dossier avec succès", 1, "INFO")
    except Exception as e:
        # Enregistre un message d'erreur dans le journal en cas d'échec de la suppression
        log_to_database(num_boucle, periode, datetime.now(), f"{dossier_path}", f"Erreur lors de la suppression du dossier : {e}", 2, "ERROR")
    
    # Filtrer les lignes où granularité = 1
    filtered_df = df[(df['Granularite'] == 1)]
     
    # Obtenir les PRM uniques après filtrage
    unique_prm = pd.concat([filtered_df['PRM_conso'], filtered_df['PRM_prod']]).dropna().unique()
     
    # Obtenir la liste des attributs uniques
    attributs_uniques = df['Attribut'].unique()
     
    # Pour chaque PRM unique et attribut unique
    for prm in unique_prm:
     for att in attributs_uniques:
         # Harmoniser le nom de l'attribut
         harmonized_att = harmonize_attribut(att)
                  
         # Trie df avec PRM_conso = prm et Attribut = att et Granu = granu
         df_prm_att = df[(df['PRM_conso'] == prm)]
         df_prm_att = df_prm_att[(df_prm_att['Attribut'] == att)]
         # Trie df avec Granu != 1
         df_prm_att = df_prm_att[df_prm_att['Granularite'] != 1]
        
         # Utiliser directement Date_debut arrondie à l'heure pour le groupement
         df_prm_att['Date_Heure'] = df_prm_att['Date_debut'].dt.floor('H')
         
         # Calculer la moyenne des valeurs par heure
         mean_values = df_prm_att.groupby(df_prm_att['Date_Heure'])['Valeur'].mean()
        
         # Calculer la somme des moyennes horaires
         sommeCDC = mean_values.sum()
         sommeCDC = sommeCDC / 1000
        
         if harmonized_att == 'Complément' or harmonized_att == 'Consommation' or harmonized_att == 'Autoproduction':
             try:
                 # Vérification de la justesse des données pour la page 3 de la feuille de calcul 'Synthèse'
                 calculer_sommeSynt_page3(df, prm, att, harmonized_att, sommeCDC, num_boucle, periode)
             except Exception as e:
                 # Enregistre un message d'erreur dans le journal en cas d'échec du calcul
                 log_to_database(num_boucle, periode, datetime.now(), "", f"Erreur lors du calcul de la somme synthèse page 3 pour {harmonized_att} avec PRM {prm} et granularité 1: {e}", 2, "ERROR")
         else:
             try:
                 # Vérification de la justesse des données pour la page 2 de la feuille de calcul 'Synthèse'
                 calculer_sommeSynt_page2(df, prm, harmonized_att, sommeCDC, num_boucle, periode)
             except Exception as e:
                 # Enregistre un message d'erreur dans le journal en cas d'échec du calcul
                 log_to_database(num_boucle, periode, datetime.now(), "", f"Erreur lors du calcul de la somme synthèse page 2 pour {harmonized_att} avec PRM {prm} et granularité 1: {e}", 2, "ERROR")
 
         if att == 'Autoconsommation':
             try:
                 # Vérification de la justesse des données pour l'autoconsommation "générale" de la page 2 de la feuille de calcul 'Synthèse'
                 calculer_sommeSynt_page2(df, prm, harmonized_att, sommeCDC, num_boucle, periode)
             except Exception as e:
                 # Enregistre un message d'erreur dans le journal en cas d'échec du calcul
                 log_to_database(num_boucle, periode, datetime.now(), "", f"Erreur lors du calcul de la somme synthèse page 2 pour {harmonized_att} avec PRM {prm} et granularité 1: {e}", 2, "ERROR")
    
    # Vérifie l'autoproduction
    verif_autoprod(df, num_boucle, periode)
     
    # Vérifie le surplus
    verif_surplus(df, num_boucle, periode)

    # Insertion des données de la df dans la table Mesure
    insert_data_to_mysql(df, num_boucle, periode)
    
    # Supprime les doublons de la table Mesure
    remove_duplicates(num_boucle, periode)
    
    # Supression des lignes de log Test de la table Log
    delete_test_logs(num_boucle, periode)
    
    # Change le répertoire de travail
    os.chdir("/home/ubuntu/CEpublicationEXPL/src")
     
    # Appelle la fonction pour exécuter un autre programme
    call_another_program(repertoire, mail, mail_password, subject, num_boucle, periode)