# df_utils.py
import os
import pandas as pd
import json
from datetime import datetime
import numpy as np
from datetime import timedelta
import re
from .regex_utils import extract_attribut, extract_prm
from .database_utils import log_to_database


def create_database_structure(num_boucle, periode):
    """
    Créer la structure de la base de données et retourner un DataFrame vide avec les colonnes définies.

    :param num_boucle (int): Numéro de la boucle d'autoconsommation.
    :param periode (str): Période (dateDebut_dateFin).
    :return (DataFrame): Un DataFrame vide avec la structure de la base de données.
    """    
    # Créer un DataFrame vide avec la structure de la base de données
    df = pd.DataFrame(columns=['Id_boucle', 'PRM_prod', 'PRM_conso', 'Attribut', 'Date_debut', 'Date_fin', 'Valeur', 'Granularite', 'Respo', 'Classe', 'Etat'])
    
    # Enregistre un message de succès une fois la structure de la base de données créée
    log_to_database(num_boucle, periode, datetime.now(), "", "DataFrame imitant la structure de la base de données créé avec succès", 1, "INFO")
    
    # Retourne le DataFrame vide avec la structure de la base de données
    return df


def process_files_in_directory(directory, id_boucle, date_debut, date_fin, periode):
    """
    Traiter les fichiers dans le répertoire spécifié et retourner une liste de DataFrames.

    :param directory (str): Chemin vers le répertoire contenant les fichiers à traiter.
    :param id_boucle (str): Identifiant de la boucle d'autoconsommation.
    :param date_debut (datetime): Date de début pour le traitement des données.
    :param date_fin (datetime): Date de fin pour le traitement des données.
    :param num_boucle (int): Numéro de la boucle d'autoconsommation.
    :param periode (str): Période (dateDebut_dateFin).
    :return (List[DataFrame]): Liste de DataFrames contenant les données traitées.
    """
    # Enregistre un message indiquant le début du traitement des fichiers dans le répertoire
    log_to_database(id_boucle, periode, datetime.now(), f"{directory}", "Traitement des fichiers dans le répertoire", 2, "INFO")
    
    # Initialise une liste pour stocker les DataFrames traités
    data_frames = []
    
    # Parcourt tous les fichiers dans le répertoire
    for file_name in os.listdir(directory):
        file_path = os.path.join(directory, file_name)
        
        # Si le fichier est un fichier CDC au format CSV
        if 'CDC' in file_name and file_name.endswith('.csv'):
            # Extraction de l'attribut et du PRM depuis le nom du fichier
            prm = extract_prm(file_name, id_boucle, periode)
            attribut = extract_attribut(file_name, id_boucle, periode)
            # Traitement du fichier CDC et ajout du DataFrame résultant à la liste
            df_cdc = process_cdc_file(file_path, id_boucle, prm, attribut, periode)
            
            data_frames.append(df_cdc)
            
        # Si le fichier est un fichier de synthèse au format Excel
        elif file_name.endswith('.xlsx'):
            if 'synthese' in file_name.lower():
                # Traitement du fichier de synthèse et mise à jour de la liste des DataFrames
                process_synthese_file(file_path, data_frames, id_boucle, date_debut, date_fin, periode)
    
    # Retourne la liste de DataFrames contenant les données traitées
    return data_frames

def process_cdc_file(file_path, id_boucle, prm, attribut, periode):
    """
    Traiter un fichier CDC et retourner un DataFrame contenant les données structurées.

    :param file_path (str): Chemin vers le fichier CDC à traiter.
    :param id_boucle (str): Identifiant de la boucle d'autoconsommation.
    :param prm (str): Point Référence Mesure du fichier à CDC à traiter.
    :param attribut (str): Attribut extrait du nom du fichier.
    :param periode (str): Période (dateDebut_dateFin).
    :return liste(DataFrame): DataFrame contenant les données structurées du fichier CDC.
    """
    file_name = os.path.basename(file_path)
    
    # Lecture du fichier CDC
    try:
        with open(file_path, 'r', newline='', encoding='utf-8') as f:
            df_cdc = pd.read_csv(f, header=None, sep=';')
    except Exception as e:
        log_to_database(id_boucle, periode, datetime.now(), f"{file_name}", f"Erreur lors de la lecture du fichier CDC : {e}", 2, "ERROR")
        return pd.DataFrame()

    
    # Création d'un DataFrame vide avec les colonnes souhaitées
    cdc_data = pd.DataFrame(columns=['Id_boucle', 'PRM_conso', 'Attribut', 'Date_debut', 'Date_fin', 'Valeur', 'Granularite'])

    # Traitement de chaque ligne du fichier CDC
    for index, row in df_cdc.iterrows():
        try:
            date_heure = datetime.strptime(row[0], "%d/%m/%Y %H:%M")
        except ValueError:
            log_to_database(id_boucle, periode, datetime.now(), f"{file_name}", f"Format de date invalide dans le fichier CDC à la ligne {index + 1}", 2, "ERROR")
            continue
        
        # Compter les colonnes non vides
        nb_colonnes_valeurs = sum(pd.notna(row[1:]))
        granularite = 60 // nb_colonnes_valeurs  # Granularité en minutes

        valeurs = row[1:nb_colonnes_valeurs + 1].tolist()  # Extraire les colonnes de valeurs
        valeurs = [float(val) for val in valeurs]  # Convertir les valeurs en float

        for i, valeur in enumerate(valeurs):
            # Calcul de la date de début et de fin pour chaque valeur
            date_debut = date_heure + timedelta(minutes=i * granularite)
            date_fin = date_heure + timedelta(minutes=(i+1) * granularite)
            
            # Si le PRM commence par 'ACC', il est considéré comme NaN
            if str(prm).startswith('ACC'):
                prm = np.nan
            # Si le PRM est NaN, il est également considéré comme NaN
            elif pd.isna(prm):
                prm = np.nan
            else:
                prm = prm

            # Création d'une ligne pour le DataFrame final
            ligne = pd.DataFrame({
                'Id_boucle': id_boucle,
                'PRM_conso': prm,
                'Attribut': attribut,
                'Date_debut': date_debut,
                'Date_fin': date_fin,
                'Valeur': valeur,
                'Granularite': nb_colonnes_valeurs
            }, index=[0])

            # Ajout de la ligne au DataFrame final
            cdc_data = pd.concat([cdc_data, ligne], ignore_index=True, join='inner')
   
    # Enregistre un message de succès une fois le fichier CDC traité
    log_to_database(id_boucle, periode, datetime.now(), f"{file_name}", "Fichier CDC traité avec succès", 2, "INFO")
    
    # Retourne le DataFrame contenant les données structurées
    return cdc_data


def process_synthese_file(file_path, data_frames, id_boucle, date_debut, date_fin, periode):
    """
    Traiter un fichier de synthèse et ajouter les DataFrames résultants à une liste de DataFrames.

    :param file_path (str): Chemin vers le fichier de synthèse à traiter.
    :param data_frames (List[DataFrame]): Liste de DataFrames à laquelle ajouter les résultats du traitement.
    :param id_boucle (str): Identifiant de la boucle d'autoconsommation.
    :param date_debut (datetime): Date de début pour le traitement des données.
    :param date_fin (datetime): Date de fin pour le traitement des données.
    :param periode (str): Période (dateDebut_dateFin).
    """
    file_name = os.path.basename(file_path)
    log_to_database(id_boucle, periode, datetime.now(), f"{file_name}", "Traitement du fichier synthèse", 2, "INFO")
    try:
        # Lecture du fichier Excel et traitement des feuilles pertinentes
        with pd.ExcelFile(file_path) as xls:
            # Lecture de la deuxième feuille
            df_sheet2 = pd.read_excel(file_path, sheet_name=xls.sheet_names[1], skiprows=2, dtype=str)
            # Identification des colonnes ID et de fusion
            id_cols = df_sheet2.columns[df_sheet2.columns.str.contains(r'(?=.*PRM)(?=.*Prod).*|(?=.*Responsable).*|(?=.*PRM)(?=.*Consommateur).*|(?=.*contrat)(?=.*Prod).*', regex=True, case=False)]
            cols_to_melt = df_sheet2.columns[df_sheet2.columns.str.contains(r'.*Production.*|.*Autoprod.*|.*Surplus.*', regex=True, case=False)]
            df_sheet2_melted = pd.melt(df_sheet2, id_vars=id_cols,
                                       value_vars=cols_to_melt,
                                       var_name='Attribut', value_name='Valeur')
            # Renommage des colonnes et conversion de la colonne 'Valeur' en float
            df_sheet2_melted = rename_columns(df_sheet2_melted, id_boucle, periode)
            df_sheet2_melted['Valeur'] = df_sheet2_melted['Valeur'].astype(float)
            
            # Traitement supplémentaire
            processed_df_sheet2 = process_synthese_sheet2(df_sheet2_melted, file_name, id_boucle, periode)
            processed_df_sheet2['Id_boucle'] = id_boucle
            processed_df_sheet2['Date_debut'] = date_debut
            processed_df_sheet2['Date_fin'] = date_fin
            processed_df_sheet2['Granularite'] = 1
            
            data_frames.append(processed_df_sheet2)

            # Lecture de la troisième feuille
            df_sheet3 = pd.read_excel(file_path, sheet_name=xls.sheet_names[2], skiprows=2, dtype=str)
            # Conversion de la colonne 'PRM Conso' en str et identification des colonnes ID et de fusion
            id_cols = df_sheet3.columns[df_sheet3.columns.str.contains(r'(?=.*PRM)(?=.*Cons).*|(?=.*Classe).*', regex=True, case=False)]
            cols_to_melt = df_sheet3.columns[df_sheet3.columns.str.contains(r'.*Consommation.*|.*Autoconso.*|.*Complément.*', regex=True, case=False)]
            df_sheet3_melted = pd.melt(df_sheet3, id_vars=id_cols,
                                       value_vars=cols_to_melt,
                                       var_name='Attribut', value_name='Valeur')
            # Renommage des colonnes et conversion de la colonne 'Valeur' en float
            df_sheet3_melted = rename_columns(df_sheet3_melted, id_boucle, periode)
            df_sheet3_melted['Valeur'] = df_sheet3_melted['Valeur'].astype(float)
            # Traitement supplémentaire
            df_sheet3_melted['Id_boucle'] = id_boucle
            df_sheet3_melted['Date_debut'] = date_debut
            df_sheet3_melted['Date_fin'] = date_fin
            df_sheet3_melted['Granularite'] = 1
            
            data_frames.append(df_sheet3_melted)
            
            log_to_database(id_boucle, periode, datetime.now(), f"{file_name}", "Fichier synthèse traité avec succès", 2, "INFO")
    except Exception as e:
        log_to_database(id_boucle, periode, datetime.now(), "f{file_name}", f"Erreur lors du traitement du fichier synthèse: {e}", 2, "ERROR")
       
       
def rename_columns(df, num_boucle, periode):
    """
    Renommer les colonnes d'un DataFrame en utilisant un mapping défini dans un fichier JSON.

    :param df (DataFrame): Le DataFrame dont les colonnes doivent être renommées.
    :param num_boucle (int): Numéro de la boucle d'autoconsommation.
    :param periode (str): Période (dateDebut_dateFin).
    :return (DataFrame): DataFrame avec les colonnes renommées.
    """
    # Charger le fichier JSON contenant le mapping
    try:
        with open('/home/ubuntu/CEpublicationEXPL/config/mappings/column_mapping.json', encoding='utf-8') as f:
            mapping = json.load(f)
    except Exception as e:
        log_to_database(num_boucle, periode, datetime.now(), "column_mapping.json", f"Erreur lors du chargement du fichier de mapping : {e}", 2, "ERROR")
        return df
    
    # Créer un dictionnaire pour mapper les anciens noms de colonnes aux nouveaux noms
    rename_dict = {}
    for new_col_name, col_patterns in mapping["column_mapping"].items():
        for pattern in col_patterns:
            for col in df.columns:
                # Vérifier si le nom de la colonne correspond à l'un des patterns dans le mapping
                if re.search(pattern, col, re.IGNORECASE):
                    rename_dict[col] = new_col_name
                    
    # Renommer les colonnes selon le dictionnaire de mapping
    df = df.rename(columns=rename_dict)
    log_to_database(num_boucle, periode, datetime.now(), "", "Colonnes du DataFrame renommées avec succès", 1, "INFO")
    return df


def harmonize_attribut(attribut):
    """
    Harmoniser un attribut en utilisant un dictionnaire de correspondance.

    :param attribut (str): L'attribut à harmoniser.
    :param mapping (Dict[String, String]): Dictionnaire de correspondance pour harmoniser l'attribut.
    :return (String): L'attribut harmonisé, ou l'attribut d'origine si aucune correspondance n'est trouvée.
    """
    # Charger le fichier JSON contenant le mapping pour harmoniser les attributs
    with open('/home/ubuntu/CEpublicationEXPL/config/mappings/attribute_mapping.json', 'r', encoding='utf-8') as file:
        mapping = json.load(file)
        
    # Utiliser le mapping pour harmoniser l'attribut
    return mapping.get(attribut, attribut)

def process_synthese_sheet2(df, file_name, num_boucle, periode):
    """
    Traiter les données de la feuille 2 du fichier de synthèse.

    :param df (DataFrame): DataFrame contenant les données de la feuille 2.
    :param num_boucle (int): Numéro de la boucle d'autoconsommation.
    :param periode (str): Période (dateDebut_dateFin).
    :return (DataFrame): DataFrame contenant les données traitées de la feuille 2.
    """
    processed_rows = [] # Initialiser une liste pour stocker les lignes traitées
    current_prm_prod = None # Initialiser le PRM_prod courant à None
    current_resp_equilibre = None # Initialiser le responsable d'équilibre courant à None
    
    # Parcourir les lignes du DataFrame
    for index, row in df.iterrows():
        # Mettre à jour le PRM_prod et le responsable d'équilibre courants s'il y a une nouvelle valeur
        if not pd.isna(row['PRM_prod']):
            current_prm_prod = str(row['PRM_prod'])
            current_resp_equilibre = row['Respo']
        
        # Harmoniser le PRM_conso
        if 'PRM_conso' in df.columns:
            if str(row['PRM_conso']).startswith('ACC'):
                prm = np.nan
            elif pd.isna(row['PRM_conso']):
                prm = np.nan
            else:
                prm = str(row['PRM_conso'])
        else :
            prm = np.nan
             
        # Ajouter la ligne traitée à la liste des lignes traitées
        processed_rows.append({
            'PRM_prod': current_prm_prod,
            'PRM_conso': prm,
            'Attribut': row['Attribut'],
            'Valeur': row['Valeur'],
            'Respo': current_resp_equilibre
        })
    
    # Créer un DataFrame à partir des lignes traitées
    processed_df = pd.DataFrame(processed_rows)
    # Supprimer les lignes avec des valeurs manquantes dans la colonne 'Valeur'
    processed_df = processed_df.dropna(subset=['Valeur'])
    
    log_to_database(num_boucle, periode, datetime.now(), f"{file_name}", "Feuille 2 du fichier synthèse traitée avec succès", 2, "INFO")
    return processed_df


def rename_attribut_values(df):
    """
    Renommer les valeurs de la colonne 'Attribut' dans un DataFrame en utilisant un mapping défini. 

    :param df (DataFrame): Le DataFrame contenant la colonne 'Attribut' à renommer.
    :return (DataFrame): DataFrame avec les valeurs de la colonne 'Attribut' renommées.
    """
    # Définir le mapping des valeurs de la colonne 'Attribut'
    mapping = {
        r'.*Autoprod.*': 'Autoproduction',
        r'.*Autoconso.*': 'Autoconsommation',
        r'.*Prod.*': 'Production',
        r'.*Conso.*': 'Consommation',
        r'.*Surplus.*': 'Surplus',
        r'.*Complement.*': 'Complement',
        # Ajoutez ici d'autres mappings pour les valeurs de la colonne 'Attribut'
    }
    
    # Renommer les valeurs de la colonne 'Attribut' en utilisant le mapping
    df['Attribut'] = df['Attribut'].replace(mapping, regex=True)
    return df


def calculer_sommeSynt_page2(df, prm, harmonized_att, sommeCDC, num_boucle, periode):
    """
    Calculer et vérifier la somme des valeurs pour les attributs harmonisés sur la page 2. Permet de vérifier la justesse des données.

    :param df (DataFrame): DataFrame contenant les données.
    :param prm (str): PRM (Point de Référence Mesure).
    :param harmonized_att (str): Attribut harmonisé (par exemple, 'Production', 'Autoproduction').
    :param sommeCDC (float): Somme calculée pour le fichier CDC à vérifier.
    :param num_boucle (int): Numéro de la boucle d'autoconsommation.
    :param periode (str): Période (dateDebut_dateFin).
    :return (None): Cette fonction ne renvoie rien. Elle modifie le DataFrame en place.
    """
    sommeSynt = 0
    
    if (harmonized_att == 'Production'):
        
        # Filtrer le DataFrame pour les attributs de production
        df_synt1 = df[(df['Granularite'] == 1)]
        df_synt1 = df_synt1[(~df_synt1['Respo'].isna())]
        df_synt1 = df_synt1[(df_synt1['PRM_prod'] == prm)]
        df_synt1 = df_synt1[df_synt1['Attribut'] == harmonized_att]
    
        # Calculer la somme des valeurs
        sommeSynt = df_synt1['Valeur'].sum()
        
        # Comparaison entre sommeSynt et sommeCDC (avec un écart accepté)
        if abs(sommeSynt - sommeCDC) < 1:
            # Mettre l'état à 'Vérifié' pour les lignes correspondantes uniquement si Etat est NaN
            affected_indices = df_synt1.index[df.loc[df_synt1.index, 'Etat'].isna()]
            df.loc[affected_indices, 'Etat'] = 'Vérifié'
            if not affected_indices.empty:
                log_to_database(num_boucle, periode, datetime.now(), "", f"Somme vérifiée pour {harmonized_att} avec PRM {prm} et granularité 1", 2, "INFO")
        else:
            # Mettre l'état à 'Non vérifié' pour les lignes correspondantes uniquement si Etat est NaN
            affected_indices = df_synt1.index[df.loc[df_synt1.index, 'Etat'].isna()]
            df.loc[affected_indices, 'Etat'] = 'Non vérifié'
            if not affected_indices.empty:
                log_to_database(num_boucle, periode, datetime.now(), "", f"Somme non vérifiée pour {harmonized_att} avec PRM {prm} et granularité 1. Différence : {abs(sommeSynt - sommeCDC)}", 2, "ERROR")
    
    elif harmonized_att == 'Autoproduction':
        # Filtrer le DataFrame pour les attributs d'autoproduction
        df_synt1 = df[(df['Granularite'] == 1)]
        df_synt1 = df_synt1[(~df_synt1['Respo'].isna())]
        df_synt1 = df_synt1[(df_synt1['PRM_conso'] == prm)]
        df_synt1 = df_synt1[df_synt1['Attribut'] == harmonized_att]
    
        # Calculer la somme des valeurs
        sommeSynt = df_synt1['Valeur'].sum()
        
        # Comparaison entre sommeSynt et sommeCDC (avec un écart accepté)
        if abs(sommeSynt - sommeCDC) < 1:
            # Mettre l'état à 'Vérifié' pour les lignes correspondantes uniquement si Etat est NaN
            affected_indices = df_synt1.index[df.loc[df_synt1.index, 'Etat'].isna()]
            df.loc[affected_indices, 'Etat'] = 'Vérifié'
            if not affected_indices.empty:
                log_to_database(num_boucle, periode, datetime.now(), "", f"Somme vérifiée pour {harmonized_att} avec PRM {prm} et granularité 1", 2, "INFO")
        else:
            # Mettre l'état à 'Non vérifié' pour les lignes correspondantes uniquement si Etat est NaN
            affected_indices = df_synt1.index[df.loc[df_synt1.index, 'Etat'].isna()]
            df.loc[affected_indices, 'Etat'] = 'Non vérifié'
            if not affected_indices.empty:
                log_to_database(num_boucle, periode, datetime.now(), "", f"Somme non vérifiée pour {harmonized_att} avec PRM {prm} et granularité 1. Différence : {abs(sommeSynt - sommeCDC)}", 2, "ERROR")


def calculer_sommeSynt_page3(df, prm, att, harmonized_att, sommeCDC, num_boucle, periode):
    """
    Calculer et vérifier la somme des valeurs pour les attributs harmonisés sur la page 3. Permet de vérifier la justesse des données.

    :param df (DataFrame): DataFrame contenant les données.
    :param prm (str): PRM (Point de Référence Mesure).
    :param att (str): Attribut original.
    :param harmonized_att (str): Attribut harmonisé (par exemple, 'Complément', 'Autoconsommation').
    :param sommeCDC (float): Somme calculée pour le fichier CDC à vérifier.
    :param num_boucle (int): Numéro de la boucle d'autoconsommation.
    :param periode (str): Période (dateDebut_dateFin).
    :return (None): Cette fonction ne renvoie rien. Elle modifie le DataFrame en place.
    """
    sommeSynt = 0
    
    if harmonized_att == 'Complément' :
        # Filtrer le DataFrame pour les attributs de Consommation et d'Autoproduction
        df_synt = df[(df['Granularite'] == 1)]
        df_synt = df_synt[(df_synt['Respo'].isna())]
        df_synt = df_synt[(df_synt['PRM_conso'] == prm)]
        
        # Calculer la somme de Consommation
        df_conso = df_synt[df_synt['Attribut'] == 'Consommation']
        sommeConso = df_conso['Valeur'].sum()
        
        # Calculer la somme d'Autoconsommation
        df_autoconso = df_synt[df_synt['Attribut'] == 'Autoconsommation']
        sommeAutoConso = df_autoconso['Valeur'].sum()
        
        # Calculer la différence entre la somme de consommation et d'autoconsommation
        diff = sommeConso - sommeAutoConso
        
        # Filtrer les données pour l'attribut spécifié
        df_synt = df_synt[df_synt['Attribut'] == harmonized_att]
    
        # Calculer la somme des valeurs
        sommeSynt = df_synt['Valeur'].sum()
        
        # Comparaison entre sommeSynt et diff (avec un écart accepté)
        if abs(sommeSynt - diff) < 1:
            # Mettre l'état à 'Vérifié' pour les lignes correspondantes uniquement si Etat est NaN
            affected_indices = df_synt.index[df.loc[df_synt.index, 'Etat'].isna()]
            df.loc[affected_indices, 'Etat'] = 'Vérifié'
            if not affected_indices.empty:
                log_to_database(num_boucle, periode, datetime.now(), "", f"Somme vérifiée pour {harmonized_att} avec PRM {prm} et granularité 1", 2, "INFO")
        else:
            # Mettre l'état à 'Non vérifié' pour les lignes correspondantes uniquement si Etat est NaN
            affected_indices = df_synt.index[df.loc[df_synt.index, 'Etat'].isna()]
            df.loc[affected_indices, 'Etat'] = 'Non vérifié'
            if not affected_indices.empty:
                log_to_database(num_boucle, periode, datetime.now(), "", f"Somme non vérifiée pour {harmonized_att} avec PRM {prm} et granularité 1. Différence : {abs(sommeSynt - diff)}", 2, "ERROR")
    else: 
        # Si l'attribut original est 'Autoconsommation', utiliser 'Autoconsommation' comme attribut harmonisé
        if att == 'Autoconsommation' : harmonized_att = 'Autoconsommation'
    
        # Filtrer le DataFrame pour les attributs d'autoconsommation
        df_synt = df[(df['Granularite'] == 1)]
        df_synt = df_synt[(df_synt['Respo'].isna())]
        df_synt = df_synt[(df_synt['PRM_conso'] == prm)]
        
        # Filtrer les données pour l'attribut spécifié
        df_synt = df_synt[df_synt['Attribut'] == harmonized_att]
        
        # Calculer la somme des valeurs
        sommeSynt = df_synt['Valeur'].sum()
    
        # Comparaison entre sommeSynt et sommeCDC (avec un écart accepté)
        if abs(sommeSynt - sommeCDC) < 1:
            # Mettre l'état à 'Vérifié' pour les lignes correspondantes uniquement si Etat est NaN
            affected_indices = df_synt.index[df.loc[df_synt.index, 'Etat'].isna()]
            df.loc[affected_indices, 'Etat'] = 'Vérifié'
            if not affected_indices.empty:
                log_to_database(num_boucle, periode, datetime.now(), "", f"Somme vérifiée pour {harmonized_att} avec PRM {prm} et granularité 1", 2, "INFO")
        else:
            # Mettre l'état à 'Non vérifié' pour les lignes correspondantes uniquement si Etat est NaN
            affected_indices = df_synt.index[df.loc[df_synt.index, 'Etat'].isna()]
            df.loc[affected_indices, 'Etat'] = 'Non vérifié'
            if not affected_indices.empty:
                log_to_database(num_boucle, periode, datetime.now(), "", f"Somme non vérifiée pour {harmonized_att} avec PRM {prm} et granularité 1. Différence : {abs(sommeSynt - sommeCDC)}", 2, "ERROR")


def verif_autoprod(df, num_boucle, periode):
    """
    Vérifie la justesse des données d'autoproduction pour les données avec une granularité de 1 et un responsable non nul.

    :param df (DataFrame): DataFrame contenant les données.
    :param num_boucle (int): Numéro de la boucle d'autoconsommation.
    :param periode (str): Période (dateDebut_dateFin).
    :return (None): Cette fonction ne renvoie rien. Elle modifie le DataFrame en place.
    """
    # Trie df pour obtenir les données de la page 2 de la feuille de calcul 'Synthèse'. Recherche d'autoproduction sans consommateur
    df_autoprod_1 = df[(df['Granularite'] == 1)]
    df_autoprod_1 = df_autoprod_1[(~df_autoprod_1['Respo'].isna())]
    df_autoprod_1 = df_autoprod_1[df_autoprod_1['Attribut'] == 'Autoproduction']
    df_autoprod_1 = df_autoprod_1[(df_autoprod_1['PRM_conso'].isna())]
    
    # Vérifier si l'état est NaN pour tous les enregistrements
    if df_autoprod_1['Etat'].isna().all():
        prm_prod = df_autoprod_1['PRM_prod'].dropna().unique()
        
        # Parcourir chaque PRM unique
        for prm in prm_prod:
            sommeAutoProd = 0
            autoProd_value = 0
            
            # Filtrer les données pour le PRM spécifique
            df_autoprod_2 = df[(df['Granularite'] == 1)]
            df_autoprod_2 = df_autoprod_2[(~df_autoprod_2['Respo'].isna())]
            df_autoprod_2 = df_autoprod_2[df_autoprod_2['Attribut'] == 'Autoproduction']
            df_autoprod_2 = df_autoprod_2[(~df_autoprod_2['PRM_conso'].isna())]
            df_autoprod_2 = df_autoprod_2[df_autoprod_2['PRM_prod'] == prm]
            
            # Calculer la somme de l'autoproduction
            if df_autoprod_2.empty:
                df_autoprod_3 = df[(df['Granularite'] == 1)]
                df_autoprod_3 = df_autoprod_3[(df_autoprod_3['Respo'].isna())]
                df_autoprod_3 = df_autoprod_3[df_autoprod_3['Attribut'] == 'Autoconsommation']
                sommeAutoProd = df_autoprod_3['Valeur'].sum()
            else : 
                sommeAutoProd = df_autoprod_2['Valeur'].sum()
                
            # Calculer la somme d'autoproduction pour ce PRM
            df_autoprod_1_prm = df_autoprod_1[df_autoprod_1['PRM_prod'] == prm]
            autoProd_value = df_autoprod_1_prm['Valeur'].sum()
             
            # Comparaison entre sommeAutoProd et autoProd_value
            if abs(sommeAutoProd - autoProd_value) < 1:
                # Mettre l'état à 'Vérifié (sans CDC)' pour les lignes correspondantes uniquement si Etat est NaN
                df.loc[df_autoprod_1_prm.index[df.loc[df_autoprod_1_prm.index, 'Etat'].isna()], 'Etat'] = 'Vérifié (sans CDC)'
                log_to_database(num_boucle, periode, datetime.now(), "", f"Autoproduction vérifiée (sans CDC) pour le PRM {prm}", 2, "INFO")
            else:
                # Mettre l'état à 'Non vérifié (sans CDC)' pour les lignes correspondantes uniquement si Etat est NaN
                df.loc[df_autoprod_1_prm.index[df.loc[df_autoprod_1_prm.index, 'Etat'].isna()], 'Etat'] = 'Non vérifié (sans CDC)'
                log_to_database(num_boucle, periode, datetime.now(), "", f"Autoproduction non vérifiée (sans CDC) pour le PRM {prm}. Écart : {abs(sommeAutoProd - autoProd_value)}", 2, "ERROR")
               
def verif_surplus(df, num_boucle, periode):
    """
    Vérifie la justesse des données de surplus pour les données avec une granularité de 1 et un responsable non nul.

    :param df (DataFrame): DataFrame contenant les données.
    :param num_boucle (int): Numéro de la boucle d'autoconsommation.
    :param periode (str): Période (dateDebut_dateFin).
    :return (DataFrame): DataFrame modifié avec les vérifications de surplus.
    """
    # Trie df pour obtenir les données de la page 2 de la feuille de calcul 'Synthèse'.
    df_surplus_1 = df[df['Granularite'] == 1]
    df_surplus_1 = df_surplus_1[~df_surplus_1['Respo'].isna()]
    df_surplus_1 = df_surplus_1[df_surplus_1['PRM_conso'].isna()]
    
    # Obtenir les PRM uniques
    prm_prod = df_surplus_1['PRM_prod'].dropna().unique()
    
    # Parcourir chaque PRM unique
    for prm in prm_prod:
        surplus = 0
        diffAutoProd = 0
        
        # Filtrer les données pour le surplus et le PRM spécifique
        df_surplus_2 = df_surplus_1[(df_surplus_1['Attribut'] == 'Surplus') & (df_surplus_1['PRM_prod'] == prm)]
        surplus = df_surplus_2['Valeur'].sum()
        
        # Filtrer les données pour l'autoproduction et la production avec le PRM spécifique
        df_autoprod = df_surplus_1[(df_surplus_1['Attribut'] == 'Autoproduction') & (df_surplus_1['PRM_prod'] == prm)]
        df_prod = df_surplus_1[(df_surplus_1['Attribut'] == 'Production') & (df_surplus_1['PRM_prod'] == prm)]
        
        # Vérifier si les données d'autoproduction et de production sont disponibles et vérifiées
        if not df_autoprod.empty and not df_prod.empty:
            if ((df_autoprod['Etat'] == 'Vérifié') | (df_autoprod['Etat'] == 'Vérifié (sans CDC)')).all() and ((df_prod['Etat'] == 'Vérifié') | (df_prod['Etat'] == 'Vérifié (sans CDC)')).all():
                autoproduction_value = df_autoprod['Valeur'].values[0]
                production_value = df_prod['Valeur'].values[0]
                diffAutoProd = production_value - autoproduction_value
                # Comparer la différence d'autoproduction avec le surplus
                if abs(diffAutoProd - surplus) < 1:
                    # Mettre l'état à 'Vérifié' pour les lignes correspondantes
                    df.loc[df_surplus_2.index, 'Etat'] = 'Vérifié (sans CDC)'
                    log_to_database(num_boucle, periode, datetime.now(), "", f"Surplus vérifiée (sans CDC) pour le PRM {prm}", 2, "INFO")
                else:
                    df.loc[df_surplus_2.index, 'Etat'] = 'Non vérifié (sans CDC)'
                    log_to_database(num_boucle, periode, datetime.now(), "", f"Surplus non vérifiée (sans CDC) pour le PRM {prm}.", 2, "ERROR")
            else:
                df.loc[df_surplus_2.index, 'Etat'] = 'Non vérifié (sans CDC)'
                log_to_database(num_boucle, periode, datetime.now(), "", f"Surplus non vérifiée (sans CDC) pour le PRM {prm}.", 2, "ERROR")
        else:
            df.loc[df_surplus_2.index, 'Etat'] = 'Non vérifié (sans CDC)'
            log_to_database(num_boucle, periode, datetime.now(), "", f"Surplus non vérifiée (sans CDC) pour le PRM {prm}.", 2, "ERROR")

    return df